### ğŸ“‚ README pentru `src/neural_network/` (ReÈ›eaua)
**FiÈ™ier:** `src/neural_network/README.md`

```markdown
# ğŸ§  Modulul 2: ReÈ›ea NeuronalÄƒ (Antrenare & Optimizare)

Acest director conÈ›ine â€inteligenÈ›aâ€ sistemului de diagnostic. Modulul este responsabil pentru antrenarea, optimizarea È™i validarea modelului Multi-Layer Perceptron (MLP) specializat Ã®n detecÈ›ia TBC È™i a Pneumoniei.

## Arhitectura Modelului 
Ãn urma experimentelor din Etapa 6, arhitectura optimÄƒ (Exp3_Balanced) a fost definitÄƒ astfel:
* **Input Layer: 20 de neuroni (corespunzÄƒtori celor 20 de simptome din chestionar).
* **Hidden Layers:**
    * Dense (64 neuroni, activare `ReLU`)
    * Dense (64 neuroni, activare `ReLU`)
    * Dense (64 neuroni, activare `ReLU`)
Batch Normalization: Pentru stabilizarea gradientului È™i accelerarea convergenÈ›ei.
Dropout (0.2): Pentru prevenirea overfitting-ului (dezactiveazÄƒ aleatoriu 20% din conexiuni).

Output Layer: 1 neuron cu activare Sigmoid (genereazÄƒ o probabilitate Ã®ntre 0 È™i 1).

< 0.5 -> Pneumonie (Clasa 0)

> 0.5 -> TBC (Clasa 1)

## ğŸ› ï¸ Scripturi
1.  **`train.py**:
    * ÃncarcÄƒ datele din `data/`.
    * AntreneazÄƒ modelul folosind optimizatorul **Adam**.
    * SalveazÄƒ modelul antrenat Ã®n `models/trained_model.keras`.
    * SalveazÄƒ metricile È™i scaler-ul.
2. optimize.py
IdentificÄƒ cea mai bunÄƒ arhitecturÄƒ prin testarea a 4 configuraÈ›ii diferite de reÈ›ele profunde
## ğŸ“ˆ PerformanÈ›Äƒ
* **AcurateÈ›e FinalÄƒ:** ~82.73%
* **TBC Recall (Sensibilitate): ~86%
* **LatenÈ›Äƒ:** ~35 ms / inferenÈ›Äƒ

## âš™ï¸ ExecuÈ›ie Antrenament
```bash
python src/neural_network/optimize.py